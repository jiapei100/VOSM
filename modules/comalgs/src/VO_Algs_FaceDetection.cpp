/****************************************************************************************************
*                                                                                                   *
*                   IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.               *
*                                                                                                   *
*   By downloading, copying, installing or using the software you agree to this license.            *
*   If you do not agree to this license, do not download, install, copy or use the software.        *
*                                                                                                   *
*                                   License Agreement                                               *
*                           For Vision Open Statistical Models                                      *
*                                                                                                   *
* Copyright (C):    2006~2021 by JIA Pei, all rights reserved.                                      *
*                                                                                                   *
*                   VOSM is free software under the terms of the GNU Lesser General Public License  *
*                   (GNU LGPL) as published by the Free Software Foundation; either version 3.0 of  *
*                   the License, or (at your option) any later version.                             *
*                   You can use it, modify it, redistribute it, etc; and redistribution and use in  *
*                   source and binary forms, with or without modification, are permitted provided   *
*                   that the following conditions are met:                                          *
*                                                                                                   *
*                   a) Redistribution's of source code must retain this whole paragraph of          *
*                   copyright notice, including this list of conditions and all the following       *
*                   contents in this copyright paragraph.                                           *
*                                                                                                   *
*                   b) Redistribution's in binary form must reproduce this whole paragraph of       *
*                   copyright notice, including this list of conditions and all the following       *
*                   contents in this copyright paragraph, and/or other materials provided with      *
*                   the distribution.                                                               *
*                                                                                                   *
*                   c) The name of the copyright holders may not be used to endorse or promote      *
*                   products derived from this software without specific prior written permission.  *
*                                                                                                   *
*                   Any publications based on this code must cite the following five papers,        *
*                   technic reports and on-line materials.                                          *
*                                                                                                   *
*                   1) P. JIA, 2D Statistical Models, Technical Report of Vision Open Working       *
*                   Group, 2st Edition, Oct 21, 2010.                                               *
*                   http://www.visionopen.com/members/jiapei/publications/pei_sm2dreport2010.pdf    *
*                                                                                                   *
*                   2) P. JIA. Audio-visual based HMI for an Intelligent Wheelchair.                *
*                   PhD thesis, University of Essex, 2010.                                          *
*                   http://www.visionopen.com/members/jiapei/publications/pei_thesischapter34.pdf   *
*                                                                                                   *
*                   3) T. Cootes and C. Taylor. Statistical models of appearance for computer       *
*                   vision. Technical report, Imaging Science and Biomedical Engineering,           *
*                   University of Manchester, March 8 2004.                                         *
*                                                                                                   *
*                   4) I. Matthews and S. Baker. Active appearance models revisited.                *
*                   International Journal of Computer Vision, 60(2):135â€“164, November 2004.         *
*                                                                                                   *
*                   5) M. B. Stegmann, Active Appearance Models: Theory, Extensions and Cases,      *
*                   http://www2.imm.dtu.dk/~aam/main/, 2000.                                        *
*                                                                                                   *
*                                                                                                   *
* Version:          0.4.0                                                                           *
* Author:           JIA Pei                                                                         *
* Contact:          jiapei@longervision.com                                                         *
* URL:              http://www.longervision.com                                                     *
* Create Date:      2010-11-04                                                                      *
* Modify Date:      2014-04-17                                                                      *
* Modify Date:      2021-05-04                                                                      *
****************************************************************************************************/

#include <iostream>
#include <cstdio>
#include "VO_FacePart.h"
#include "VO_FaceKeyPoint.h"
#include "VO_Algs_FaceDetection.h"


/** Initialization, only initialize for face detection, excluding face parts detection */
void CFaceDetectionAlgs::init(const std::string& str, unsigned int mtd)
{
    CDetectionAlgs::init(str, mtd);

    this->m_vDetectedFaceRects.clear();
    this->m_iFaceType                   = UNDETECTED;
    this->m_bFaceDetected               = false;
    this->m_bLeftEyeDetected            = false;
    this->m_bRightEyeDetected           = false;
    this->m_bNoseDetected               = false;
    this->m_bMouthDetected              = false;
}


/** constructor */
CFaceDetectionAlgs::CFaceDetectionAlgs(const std::string& str, unsigned int mtd)
{
    this->init(str, mtd);
}


/** destructor */
CFaceDetectionAlgs::~CFaceDetectionAlgs()
{
    
}


/** 
 * @author      JIA Pei
 * @version     2010-02-04
 * @brief       Set detection configuration
 * @param       strfrontalface      Input - XML for frontal face
 * @param       strprofileface      Input - XML for profile face
 * @param       strlefteye          Input - XML for left eye
 * @param       strrighteye         Input - XML for right eye
 * @param       strnose             Input - XML for nose
 * @param       strmouth            Input - XML for mouth
 * @param       mtd                 Input - detection method
 * @return      facetype            Input - face type, frontal or profile, etc.
*/
void CFaceDetectionAlgs::SetConfiguration(  const std::string& strfrontalface,
                                            const std::string& strprofileface,
                                            const std::string& strlefteye,
                                            const std::string& strrighteye,
                                            const std::string& strnose,
                                            const std::string& strmouth,
                                            unsigned int mtd,
                                            unsigned int facetype)
{
    this->m_iDetectionMethod        = mtd;
    this->m_iFaceType               = facetype;
    switch(this->m_iDetectionMethod)
    {
        case VO_AdditiveStrongerClassifier::BAGGING:
        {
            if(strfrontalface!="")
            {
                this->m_sFile2BLoadFrontalFace    = strfrontalface;
                cv::FileStorage file(this->m_sFile2BLoadFrontalFace, cv::FileStorage::READ);
                this->m_rtreeClassifierProfileFace->read(file.root());
            }
            if(strprofileface!="")
            {
                this->m_sFile2BLoadProfileFace  = strprofileface;
                cv::FileStorage file(this->m_sFile2BLoadProfileFace, cv::FileStorage::READ);
                this->m_rtreeClassifierProfileFace->read( file.root() );
            }
            if(strlefteye!="")
            {
                this->m_sFile2BLoadLeftEye      = strlefteye;
                cv::FileStorage file(this->m_sFile2BLoadLeftEye, cv::FileStorage::READ);
                this->m_rtreeClassifierLeftEye->read( file.root() );
            }
            if(strrighteye!="")
            {
                this->m_sFile2BLoadRightEye     = strrighteye;
                cv::FileStorage file(this->m_sFile2BLoadRightEye, cv::FileStorage::READ);
                this->m_rtreeClassifierRightEye->read( file.root() );
            }
            if(strnose!="")
            {
                this->m_sFile2BLoadNose         = strnose;
                cv::FileStorage file(this->m_sFile2BLoadNose, cv::FileStorage::READ);
                this->m_rtreeClassifierNose->read( file.root() );
            }
            if(strmouth!="")
            {
                this->m_sFile2BLoadMouth        = strmouth;
                cv::FileStorage file(this->m_sFile2BLoadMouth, cv::FileStorage::READ);
                this->m_rtreeClassifierMouth->read( file.root() );
            }
        }
        break;
        case VO_AdditiveStrongerClassifier::BOOSTING:
        default:
        {
            if(strfrontalface!="")
            {
                this->m_sFile2BLoadFrontalFace  = strfrontalface;
                this->m_cascadeClassifierFrontalFace.load( this->m_sFile2BLoadFrontalFace );
            }
            if(strprofileface!="")
            {
                this->m_sFile2BLoadProfileFace  = strprofileface;
                this->m_cascadeClassifierProfileFace.load( this->m_sFile2BLoadProfileFace );
            }
            if(strlefteye!="")
            {
                this->m_sFile2BLoadLeftEye      = strlefteye;
                this->m_cascadeClassifierLeftEye.load( this->m_sFile2BLoadLeftEye );
            }
            if(strrighteye!="")
            {
                this->m_sFile2BLoadRightEye     = strrighteye;
                this->m_cascadeClassifierRightEye.load( this->m_sFile2BLoadRightEye );
            }
            if(strnose!="")
            {
                this->m_sFile2BLoadNose         = strnose;
                this->m_cascadeClassifierNose.load( this->m_sFile2BLoadNose );
            }
            if(strmouth!="")
            {
                this->m_sFile2BLoadMouth        = strmouth;
                this->m_cascadeClassifierMouth.load( this->m_sFile2BLoadMouth );
            }
        }
        break;
    }
}


/** 
 * @author      JIA Pei
 * @version     2010-02-04
 * @brief       Face Detection  -- refer to CDetectionAlgs::Detection
 * @param       iImg            Input - image to be searched within
 * @param       confinedArea    Input - only detecting the object within this confined area
 * @param       scale           Input - scalar for img scaling
 * @param       smallSize       Input - detected object should be bigger than smallsize
 * @param       bigSize         Input - detected object should be smaller than bigSize
 * @return      double          Return - the entire detection time
*/
double CFaceDetectionAlgs::FaceDetection(const cv::Mat& iImg,
                                        const cv::Rect* confinedArea,
                                        const double scale,
                                        cv::Size smallSize,
                                        cv::Size bigSize)
{
    double res = (double)cv::getTickCount();
    
    switch(this->m_iDetectionMethod)
    {
        case VO_AdditiveStrongerClassifier::BAGGING:
            CDetectionAlgs::BaggingDetection( this->m_rtreeClassifierFrontalFace,
                                            iImg,
                                            confinedArea,
                                            this->m_vDetectedFaceRects,
                                            scale,
                                            smallSize,
                                            bigSize);
        break;
        case VO_AdditiveStrongerClassifier::BOOSTING:
            CDetectionAlgs::BoostingDetection( &this->m_cascadeClassifierFrontalFace,
                                            iImg,
                                            confinedArea,
                                            this->m_vDetectedFaceRects,
                                            scale,
                                            smallSize,
                                            bigSize);
        break;
    }
    
    if ( this->m_vDetectedFaceRects.size() > 0 )
    {
        this->m_bFaceDetected = true;
        this->m_VOFaceComponents.SetObjectRect( this->m_vDetectedFaceRects[0] );
        this->m_CVDetectedFaceImagePatch4SM = iImg(this->m_VOFaceComponents.m_rectObject );
    }
    else
        this->m_bFaceDetected = false;

    res = ((double)cv::getTickCount() - res) / ((double)cv::getTickFrequency()*1000.);
    return res;
}


/**
 * @author      JIA Pei
 * @version     2008-03-04
 * @brief       Face Detection
 * @param       iImg            Input - the input image, in which the face detection will be carried out
 * @param       confinedArea    Input - only detecting the object within this confined area
 * @param       lefteye         Input - whether to detect lefteye?
 * @param       righteye        Input - whether to detect righteye?
 * @param       nose            Input - whether to detect nose?
 * @param       mouth           Input - whether to detect mouth?
 * @param       scale           Input - always 1.0
 * @param       smallSize       Input - smallest face 
 * @param       bigSize         Input - biggest face
 * @return      double          Return - the entire detection time
 * @note        This function defaultly detect face
*/
double CFaceDetectionAlgs::FullFaceDetection (  const cv::Mat& iImg,
                                                const cv::Rect* confinedArea,
                                                bool lefteye,
                                                bool righteye,
                                                bool nose,
                                                bool mouth,
                                                const double scale,
                                                cv::Size smallSize,
                                                cv::Size bigSize )
{
    double res = (double)cv::getTickCount();

    // Save image to be detected
    // cv::imwrite("tobedetected.jpg", iImg);
    
    this->FaceDetection(iImg, confinedArea, scale, smallSize, bigSize);
    if ( this->m_vDetectedFaceRects.size() > 0 )
    {
        this->m_bFaceDetected = true;
        this->m_VOFaceComponents.SetObjectRect( this->m_vDetectedFaceRects[0] );
        this->m_CVDetectedFaceWindow4SM = this->m_vDetectedFaceRects[0];
        this->m_CVDetectedFaceImagePatch4SM = iImg(this->m_VOFaceComponents.m_rectObject );
    }
    else
    {
        this->m_bFaceDetected = false;
    }

    // if detected
    if(this->m_bFaceDetected)
    {
        // Save Detected Face Image Patch
        // cv::imwrite("detectedface.jpg", this->m_CVDetectedFaceImagePatch4SM);
        this->VO_FaceComponentsDetection(this->m_CVDetectedFaceImagePatch4SM,
                                        this->m_iFaceType,
                                        lefteye,
                                        righteye,
                                        nose,
                                        mouth);
    }
    else
    {
        this->m_bLeftEyeDetected = false;
        this->m_bRightEyeDetected = false;
        this->m_bNoseDetected = false;
        this->m_bMouthDetected = false;
    }

    res = ((double)cv::getTickCount() - res) / ((double)cv::getTickFrequency()*1000.);
    return res;
}


/** 
 * @author      JIA Pei
 * @version     2010-02-04
 * @brief       Set detection configuration
 * @param       iImg            Input - input image, a face
 * @param       faceOrient      Input - face orientation
 * @param       lefteye         Input - whether to detect left eye
 * @param       righteye        Input - whether to detect right eye
 * @param       nose            Input - whether to detect nose
 * @param       mouth           Input - whether to detect mouth
*/
double CFaceDetectionAlgs::VO_FaceComponentsDetection(  const cv::Mat& iImg,
                                                        int faceOrient,
                                                        bool lefteye,
                                                        bool righteye,
                                                        bool nose,
                                                        bool mouth)
{
    double res = (double)cv::getTickCount();

    // Emphasized by JIA Pei, make sure you update m_CVDetectedFaceWindow finally!
    // set the top left half to look for left eye
    if ( lefteye )
    {
        this->m_CVLeftEyePossibleWindow = CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(iImg.cols, iImg.rows, VO_FacePart::LEFTEYE, faceOrient);
        this->m_bLeftEyeDetected = this->VO_FacePartDetection ( iImg, this->m_CVLeftEyePossibleWindow, this->m_VOFaceComponents.m_rectLeftEye, VO_FacePart::LEFTEYE);

        if ( this->m_bLeftEyeDetected )
        {
            this->m_VOFaceComponents.m_rectLeftEye.x = ( int ) ( this->m_VOFaceComponents.m_rectLeftEye.x + this->m_CVLeftEyePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectLeftEye.y = ( int ) ( this->m_VOFaceComponents.m_rectLeftEye.y + this->m_CVLeftEyePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectLeftEye.width = ( int ) ( this->m_VOFaceComponents.m_rectLeftEye.width );
            this->m_VOFaceComponents.m_rectLeftEye.height = ( int ) ( this->m_VOFaceComponents.m_rectLeftEye.height );
        }
        else
        {
            this->m_VOFaceComponents.m_rectLeftEye.x = ( int ) ( this->m_CVLeftEyePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectLeftEye.y = ( int ) ( this->m_CVLeftEyePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectLeftEye.width = ( int ) ( this->m_CVLeftEyePossibleWindow.width );
            this->m_VOFaceComponents.m_rectLeftEye.height = ( int ) ( this->m_CVLeftEyePossibleWindow.height);
        }
    }

    // set the top right half to look for right eye
    if ( righteye )
    {
        this->m_CVRightEyePossibleWindow = CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(iImg.cols, iImg.rows, VO_FacePart::RIGHTEYE, faceOrient);
        this->m_bRightEyeDetected = this->VO_FacePartDetection ( iImg, this->m_CVRightEyePossibleWindow, this->m_VOFaceComponents.m_rectRightEye, VO_FacePart::RIGHTEYE );

        if ( this->m_bRightEyeDetected )
        {
            this->m_VOFaceComponents.m_rectRightEye.x = ( int ) ( this->m_VOFaceComponents.m_rectRightEye.x + this->m_CVRightEyePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectRightEye.y = ( int ) ( this->m_VOFaceComponents.m_rectRightEye.y + this->m_CVRightEyePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectRightEye.width = ( int ) ( this->m_VOFaceComponents.m_rectRightEye.width );
            this->m_VOFaceComponents.m_rectRightEye.height = ( int ) ( this->m_VOFaceComponents.m_rectRightEye.height);
        }
        else
        {
            this->m_VOFaceComponents.m_rectRightEye.x = ( int ) ( this->m_CVRightEyePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectRightEye.y = ( int ) ( this->m_CVRightEyePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectRightEye.width = ( int ) ( this->m_CVRightEyePossibleWindow.width );
            this->m_VOFaceComponents.m_rectRightEye.height = ( int ) ( this->m_CVRightEyePossibleWindow.height );
        }
    }

    if ( nose )
    {
        this->m_CVNosePossibleWindow = CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(iImg.cols, iImg.rows, VO_FacePart::NOSE, faceOrient);
        this->m_bNoseDetected = this->VO_FacePartDetection ( iImg, this->m_CVNosePossibleWindow, this->m_VOFaceComponents.m_rectNose, VO_FacePart::NOSE );

        if ( this->m_bNoseDetected )
        {
            this->m_VOFaceComponents.m_rectNose.x = ( int ) ( this->m_VOFaceComponents.m_rectNose.x + this->m_CVNosePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectNose.y = ( int ) ( this->m_VOFaceComponents.m_rectNose.y + this->m_CVNosePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectNose.width = ( int ) ( this->m_VOFaceComponents.m_rectNose.width );
            this->m_VOFaceComponents.m_rectNose.height = ( int ) ( this->m_VOFaceComponents.m_rectNose.height );
        }
        else
        {
            this->m_VOFaceComponents.m_rectNose.x = ( int ) ( this->m_CVNosePossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectNose.y = ( int ) ( this->m_CVNosePossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectNose.width = ( int ) ( this->m_CVNosePossibleWindow.width );
            this->m_VOFaceComponents.m_rectNose.height = ( int ) ( this->m_CVNosePossibleWindow.height );
        }
    }

    if ( mouth )
    {
        this->m_CVMouthPossibleWindow = CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(iImg.cols, iImg.rows, VO_FacePart::LIPOUTERLINE, faceOrient);
        this->m_bMouthDetected = this->VO_FacePartDetection ( iImg, this->m_CVMouthPossibleWindow, this->m_VOFaceComponents.m_rectMouth, VO_FacePart::LIPOUTERLINE );

        if ( this->m_bMouthDetected )
        {
            this->m_VOFaceComponents.m_rectMouth.x = ( int ) ( this->m_VOFaceComponents.m_rectMouth.x + this->m_CVMouthPossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectMouth.y = ( int ) ( this->m_VOFaceComponents.m_rectMouth.y + this->m_CVMouthPossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectMouth.width = ( int ) ( this->m_VOFaceComponents.m_rectMouth.width );
            this->m_VOFaceComponents.m_rectMouth.height = ( int ) ( this->m_VOFaceComponents.m_rectMouth.height );
        }
        else
        {
            this->m_VOFaceComponents.m_rectMouth.x = ( int ) ( this->m_CVMouthPossibleWindow.x + this->m_CVDetectedFaceWindow4SM.x );
            this->m_VOFaceComponents.m_rectMouth.y = ( int ) ( this->m_CVMouthPossibleWindow.y + this->m_CVDetectedFaceWindow4SM.y );
            this->m_VOFaceComponents.m_rectMouth.width = ( int ) ( this->m_CVMouthPossibleWindow.width );
            this->m_VOFaceComponents.m_rectMouth.height = ( int ) ( this->m_CVMouthPossibleWindow.height );
        }
    }

    // Default logical relationship among all the above 4 face parts
    // According to my observation, the mouth some times goes wrong.
    // the nose x direction goes wrong some times, but y direction keeps correct
    if ( this->m_bNoseDetected && this->m_bMouthDetected ) // mouth must be lower than nose
    {
        if ( this->m_VOFaceComponents.m_rectMouth.y+1.0f*this->m_VOFaceComponents.m_rectMouth.height/2.0f <= ( this->m_VOFaceComponents.m_rectNose.y + this->m_VOFaceComponents.m_rectNose.height ) )
            this->m_VOFaceComponents.m_rectMouth.y += this->m_VOFaceComponents.m_rectMouth.height;
        if ( this->m_VOFaceComponents.m_rectMouth.y+1.0f*this->m_VOFaceComponents.m_rectMouth.height/2.0f <= ( this->m_VOFaceComponents.m_rectNose.y + this->m_VOFaceComponents.m_rectNose.height ) )
            this->m_VOFaceComponents.m_rectMouth.y += this->m_VOFaceComponents.m_rectMouth.height;
    }

    res = ((double)cv::getTickCount() - res) / ((double)cv::getTickFrequency()*1000.);
    return res;
}


/**
 * @author      JIA Pei
 * @version     2010-02-04
 * @brief       Face Component Detection
 * @param       iImg        Input - the input image, in which the face detection will be carried out
 *                                - Here, make sure iImg is gray level image
 * @param       iWindow     Input - Possible input face part window, in which this face part is in
 * @param       oWindow     Output - Output detected face part window
 * @param       facepart    Input - Which face part is it to be detected in. VO_FacePart::LEFTEYE, VO_FacePart::RIGHTEYE, VO_FacePart::NOSE, MOUTH
 * @return      bool        Return - Whether the face component has been detected or not
*/
bool CFaceDetectionAlgs::VO_FacePartDetection (const cv::Mat& iImg,
                                               const cv::Rect& iWindow,
                                               cv::Rect& oWindow,
                                               unsigned int facepart)
{
    bool result = false;
    cv::Mat smallImgROI = iImg(iWindow);
 
    std::vector<cv::Rect> detectedfp;
    switch ( facepart )
    {
        case VO_FacePart::LEFTEYE:
        {
            // cv::imwrite("lefteye.jpg", smallImgROI);
            switch(this->m_iDetectionMethod)
            {
                case VO_AdditiveStrongerClassifier::BAGGING:
                    CDetectionAlgs::BaggingDetection(this->m_rtreeClassifierLeftEye,
                                                    smallImgROI,
                                                    0,
                                                    detectedfp,
                                                    1.0,
                                                    cv::Size(smallImgROI.cols/4, smallImgROI.rows/8),
                                                    cv::Size(smallImgROI.cols, smallImgROI.rows*2/3) );
                break;
                case VO_AdditiveStrongerClassifier::BOOSTING:
                    CDetectionAlgs::BoostingDetection(  &this->m_cascadeClassifierLeftEye,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/4, smallImgROI.rows/8),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows*2/3) );
                break;
            }
        }
        break;
        case VO_FacePart::RIGHTEYE:
        {
            // cv::imwrite("righteye.jpg", smallImgROI);
            switch(this->m_iDetectionMethod)
            {
                case VO_AdditiveStrongerClassifier::BAGGING:
                    CDetectionAlgs::BaggingDetection(   this->m_rtreeClassifierRightEye,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/4, smallImgROI.rows/8),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows*2/3) );
                break;
                case VO_AdditiveStrongerClassifier::BOOSTING:
                    CDetectionAlgs::BoostingDetection(  &this->m_cascadeClassifierRightEye,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/4, smallImgROI.rows/8),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows*2/3) );
                break;
            }
        }
        break;
        case VO_FacePart::NOSE:
        {
            // cv::imwrite("nose.jpg", smallImgROI);
            switch(this->m_iDetectionMethod)
            {
                case VO_AdditiveStrongerClassifier::BAGGING:
                    CDetectionAlgs::BaggingDetection( this->m_rtreeClassifierNose,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/6, smallImgROI.rows/6),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows) );
                break;
                case VO_AdditiveStrongerClassifier::BOOSTING:
                    CDetectionAlgs::BoostingDetection( &this->m_cascadeClassifierNose,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/6, smallImgROI.rows/6),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows) );
                break;
            }
        }
        break;
        case VO_FacePart::LIPOUTERLINE:
        {
            // cv::imwrite("lipouterline.jpg", smallImgROI);
            switch(this->m_iDetectionMethod)
            {
                case VO_AdditiveStrongerClassifier::BAGGING:
                    CDetectionAlgs::BaggingDetection( this->m_rtreeClassifierMouth,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/6, smallImgROI.rows/6),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows) );
                break;
                case VO_AdditiveStrongerClassifier::BOOSTING:
                    CDetectionAlgs::BoostingDetection( &this->m_cascadeClassifierMouth,
                                                        smallImgROI,
                                                        0,
                                                        detectedfp,
                                                        1.0,
                                                        cv::Size(smallImgROI.cols/6, smallImgROI.rows/6),
                                                        cv::Size(smallImgROI.cols, smallImgROI.rows) );
                break;
            }
        }
        break;
    }

    // Within one specific face, for face components, we only detect 1 !! And just 1 !
    if ( detectedfp.size() >= 1 )
    {
        oWindow = detectedfp[0];
        result = true;
    }
    else
    {
        oWindow = iWindow;
        result = false;
    }

    return result;
}


/**
 * @brief       detect face directions
 * @param       faceOrient  -- frontal
 * @return      int         -- face directions
 */
int CFaceDetectionAlgs::VO_DetectFaceDirection(int faceOrient)
{
    if(this->m_bFaceDetected && this->m_bLeftEyeDetected && this->m_bRightEyeDetected && this->m_bNoseDetected)
    {
        this->m_CVNoseCentralArea = CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(
                                    this->m_CVDetectedFaceImagePatch4SM.cols,
                                    this->m_CVDetectedFaceImagePatch4SM.rows,
                                    VO_FacePart::NOSECENTRALAREA,
                                    faceOrient);
        return CFaceDetectionAlgs::VO_DetectFaceDirection(  this->m_VOFaceComponents,
                                                            this->m_CVNosePossibleWindow,
                                                            this->m_CVNoseCentralArea);
    }
    else
        return CFaceDetectionAlgs::UNDETECTED;
}


/**
 * @brief   Detect Face Directions
 * @param   facecomponents    -- input, face components positions
 * @param   possiblenose      -- input, possible nose position, a rectangle
 * @param   nosecentralarea   -- input, detected nose central area, a rectangle
 * @return  int -- face directions
 */
int CFaceDetectionAlgs::VO_DetectFaceDirection( const VO_FaceCompPos& facecomponents,
                                                const cv::Rect& possiblenose,
                                                const cv::Rect& nosecentralarea)
{
    int dir = CFaceDetectionAlgs::DIR_FRONTAL;

    int leftright = 0;
    int updown = 0;

    std::vector<cv::Point2f>    centers = facecomponents.VO_CalcFaceComponentsCenters();
    float middleX = (centers[1].x + centers[2].x)/2.0;
    cv::Point2f possiblenoseCenter;
    possiblenoseCenter.x = possiblenose.x + possiblenose.width/2.0f;
    possiblenoseCenter.y = possiblenose.y + possiblenose.height/2.0f;

    // centers[3] is the nose center
    if(centers[3].x < nosecentralarea.x && centers[3].x < middleX)
        leftright = -1;    // from the user to the laptop screen, left; but actually right
    if(centers[3].x > nosecentralarea.x+nosecentralarea.width && centers[3].x > middleX)
        leftright = 1;     // from the user to the laptop screen, right; but actually left
    if(centers[3].y < nosecentralarea.y && centers[3].y < possiblenoseCenter.y)
        updown = -1;     // up
    if(centers[3].y > nosecentralarea.y+nosecentralarea.height && centers[3].y > possiblenoseCenter.y)
        updown = 1;     // down

    if( leftright == 0 && updown == 1)          dir = DIR_DOWNFRONTAL;
    if( leftright == 1 && updown == 1)          dir = DIR_DOWNLEFT;
    if( leftright == -1 && updown == 1)         dir = DIR_DOWNRIGHT;
    if( leftright == 0 && updown == -1)         dir = DIR_UPFRONTAL;
    if( leftright == 1 && updown == -1)         dir = DIR_UPLEFT;
    if( leftright == -1 && updown == -1)        dir = DIR_UPRIGHT;
    if( leftright == 1 && updown == 0)          dir = DIR_LEFT;
    if( leftright == -1 && updown == 0)         dir = DIR_RIGHT;
    if( leftright == 0 && updown == 0)          dir = DIR_FRONTAL;

    return dir;
}


/**
 * @author         JIA Pei
 * @version        2008-03-04
 * @brief          Draw face detection parts
 * @param          ioImg        Input & Output - the input image, in which the face detection will be carried out
 * @param          face         Input - whether to detect face? always true!
 * @param          lefteye      Input - whether to detect lefteye?
 * @param          righteye     Input - whether to detect righteye?
 * @param          nose         Input - whether to detect nose?
 * @param          mouth        Input - whether to detect mouth?
 * @param          color        Input - line color
*/
void CFaceDetectionAlgs::VO_DrawDetection ( cv::Mat& ioImg,
                                            bool face,  
                                            bool lefteye, 
                                            bool righteye, 
                                            bool nose, 
                                            bool mouth,
                                            cv::Scalar color)
{
    cv::Point pt1, pt2, pt;

    // Face
    if ( face )
    {
//        pt1.x = this->m_VOFaceComponents.m_rectObject.x;
//        pt1.y = this->m_VOFaceComponents.m_rectObject.y;
//        pt2.x = this->m_VOFaceComponents.m_rectObject.x + this->m_VOFaceComponents.m_rectObject.width;
//        pt2.y = this->m_VOFaceComponents.m_rectObject.y + this->m_VOFaceComponents.m_rectObject.height;
//        cv::rectangle( ioImg, pt1, pt2, color, 2, 8, 0 );

        pt1.x = this->m_CVDetectedFaceWindow4SM.x;
        pt1.y = this->m_CVDetectedFaceWindow4SM.y;
        pt2.x = this->m_CVDetectedFaceWindow4SM.x + this->m_CVDetectedFaceWindow4SM.width;
        pt2.y = this->m_CVDetectedFaceWindow4SM.y + this->m_CVDetectedFaceWindow4SM.height;
        cv::rectangle( ioImg, pt1, pt2, color, 2, 8, 0 );
    }

    // Left eye
    if ( lefteye )
    {
        pt1.x = this->m_VOFaceComponents.m_rectLeftEye.x;
        pt1.y = this->m_VOFaceComponents.m_rectLeftEye.y;
        pt2.x = this->m_VOFaceComponents.m_rectLeftEye.x + this->m_VOFaceComponents.m_rectLeftEye.width;
        pt2.y = this->m_VOFaceComponents.m_rectLeftEye.y + this->m_VOFaceComponents.m_rectLeftEye.height;
        cv::rectangle ( ioImg, pt1, pt2, colors[1], 1, 8, 0 );
    }

    // Right eye
    if ( righteye )
    {
        pt1.x = this->m_VOFaceComponents.m_rectRightEye.x;
        pt1.y = this->m_VOFaceComponents.m_rectRightEye.y;
        pt2.x = this->m_VOFaceComponents.m_rectRightEye.x + this->m_VOFaceComponents.m_rectRightEye.width;
        pt2.y = this->m_VOFaceComponents.m_rectRightEye.y + this->m_VOFaceComponents.m_rectRightEye.height;
        cv::rectangle ( ioImg, pt1, pt2, colors[2], 1, 8, 0 );
    }

    // Nose
    if ( nose )
    {
        pt1.x = this->m_VOFaceComponents.m_rectNose.x;
        pt1.y = this->m_VOFaceComponents.m_rectNose.y;
        pt2.x = this->m_VOFaceComponents.m_rectNose.x + this->m_VOFaceComponents.m_rectNose.width;
        pt2.y = this->m_VOFaceComponents.m_rectNose.y + this->m_VOFaceComponents.m_rectNose.height;
        cv::rectangle ( ioImg, pt1, pt2, colors[3], 1, 8, 0 );
    }

    // Mouth
    if ( mouth )
    {
        pt1.x = this->m_VOFaceComponents.m_rectMouth.x;
        pt1.y = this->m_VOFaceComponents.m_rectMouth.y;
        pt2.x = this->m_VOFaceComponents.m_rectMouth.x + this->m_VOFaceComponents.m_rectMouth.width;
        pt2.y = this->m_VOFaceComponents.m_rectMouth.y + this->m_VOFaceComponents.m_rectMouth.height;
        cv::rectangle ( ioImg, pt1, pt2, colors[4], 1, 8, 0 );
    }
}


/**
 * @brief Calculate Face Keypoints
 */
void CFaceDetectionAlgs::CalcFaceKeyPoints()
{
    if(this->m_bFaceDetected)
    {
        this->m_CVDetectedCenterOfGravity.x = this->m_VOFaceComponents.m_rectObject.x + (double)this->m_VOFaceComponents.m_rectObject.width/2.0;
        this->m_CVDetectedCenterOfGravity.y = this->m_VOFaceComponents.m_rectObject.y + (double)this->m_VOFaceComponents.m_rectObject.height/2.0;

//        No matter the face components have been detected or not, m_VOFaceComponents always have some values !
//        if(this->m_bLeftEyeDetected)
        {
            this->m_CVDetectedLeftEyeCenter.x = this->m_VOFaceComponents.m_rectLeftEye.x + (double)this->m_VOFaceComponents.m_rectLeftEye.width/2.0;
            this->m_CVDetectedLeftEyeCenter.y = this->m_VOFaceComponents.m_rectLeftEye.y + (double)this->m_VOFaceComponents.m_rectLeftEye.height/2.0;
            
            //this->m_CVDetectedLeftEyeLeftCorner
            //this->m_CVDetectedLeftEyeRightCorner
        }

//        if(this->m_bRightEyeDetected)
        {
            this->m_CVDetectedRightEyeCenter.x = this->m_VOFaceComponents.m_rectRightEye.x + (double)this->m_VOFaceComponents.m_rectRightEye.width/2.0;
            this->m_CVDetectedRightEyeCenter.y = this->m_VOFaceComponents.m_rectRightEye.y + (double)this->m_VOFaceComponents.m_rectRightEye.height/2.0;
            
            //this->m_CVDetectedRightEyeLeftCorner
            //this->m_CVDetectedRightEyeRightCorner
        }
        
//        if(this->m_bNoseDetected)
        {
            this->m_CVDetectedNoseCenter.x = this->m_VOFaceComponents.m_rectNose.x + (double)this->m_VOFaceComponents.m_rectNose.width/2.0;
            this->m_CVDetectedNoseCenter.y = this->m_VOFaceComponents.m_rectNose.y + (double)this->m_VOFaceComponents.m_rectNose.height/2.0;
            
            //this->m_CVDetectedNoseTip
            //this->m_CVDetectedNostrilLeft
            //this->m_CVDetectedNostrilRight
        }
        
//        if(this->m_bMouthDetected)
        {
            this->m_CVDetectedMouthCenter.x = this->m_VOFaceComponents.m_rectMouth.x + (double)this->m_VOFaceComponents.m_rectMouth.width/2.0;
            this->m_CVDetectedMouthCenter.y = this->m_VOFaceComponents.m_rectMouth.y + (double)this->m_VOFaceComponents.m_rectMouth.height/2.0;
            
            //this->m_CVDetectedMouthLeftCorner
            //this->m_CVDetectedMouthRightCorner
        }
    }
}


/**
 * @brief       Get detected face key points
 * @param       ptType      point type, which point is it?
 * @return      Point2f     the point coordinates
 */
cv::Point2f    CFaceDetectionAlgs::GetDetectedFaceKeyPoint(unsigned int ptType) const
{
    switch(ptType)
    {
        case VO_KeyPoint::CENTEROFGRAVITY:
            return    this->m_CVDetectedCenterOfGravity;
        case VO_KeyPoint::LEFTEYELEFTCORNER:
            return    this->m_CVDetectedLeftEyeLeftCorner;
        case VO_KeyPoint::LEFTEYERIGHTCORNER:
            return    this->m_CVDetectedLeftEyeRightCorner;
        case VO_KeyPoint::LEFTEYECENTER:
            return     this->m_CVDetectedLeftEyeCenter;
        case VO_KeyPoint::RIGHTEYELEFTCORNER:
            return     this->m_CVDetectedRightEyeLeftCorner;
        case VO_KeyPoint::RIGHTEYERIGHTCORNER:
            return     this->m_CVDetectedRightEyeRightCorner;
        case VO_KeyPoint::RIGHTEYECENTER:
            return     this->m_CVDetectedRightEyeCenter;
        case VO_KeyPoint::NOSETIPKEY:
            return    this->m_CVDetectedNoseTip;
        case VO_KeyPoint::NOSTRILLEFT:
            return     this->m_CVDetectedNostrilLeft;
        case VO_KeyPoint::NOSTRILRIGHT:
            return     this->m_CVDetectedNostrilRight;
        case VO_KeyPoint::NOSECENTER:
            return     this->m_CVDetectedNoseCenter;
        case VO_KeyPoint::MOUTHLEFTCORNER:
            return     this->m_CVDetectedMouthLeftCorner;
        case VO_KeyPoint::MOUTHRIGHTCORNER:
            return     this->m_CVDetectedMouthRightCorner;
        case VO_KeyPoint::MOUTHCENTER:
            return     this->m_CVDetectedMouthCenter;
    }
}


/**
 * @author        Yao Wei
 * @param         imgSize       image size
 * @param         iFaceRect     the detected face rectangle
 * @return        Rect          the adjusted face rectangle
 */
//cv::Rect CFaceDetectionAlgs::VO_FaceRectFromDetection2SM (const cv::Size& imgSize,
//                                                          const cv::Rect& iFaceRect )
//{
//    cv::Rect res;
//
//    // Note: copied from aamlibrary and asmlibrary
//    static const float CONF_VjHeightShift = 0.15f;      // shift height down by 15%
//    static const float CONF_VjShrink      = 0.80f;       // shrink size of VJ box by 20%
//
//    float xMin      = iFaceRect.x;
//    float yMin      = iFaceRect.y;
//    float xMax      = iFaceRect.x + iFaceRect.width;
//    float yMax      = iFaceRect.y + iFaceRect.height;
//
//    float NewWidth  = CONF_VjShrink * iFaceRect.width;
//    float NewHeight = CONF_VjShrink * iFaceRect.height;
//
//    float yMean     = ( yMin + yMax ) / 2;
//    yMean           += CONF_VjHeightShift * NewHeight;    // move face down
//    float xMean     = ( xMin + xMax ) / 2;
//
//    res.x           = xMean - 0.5f * NewWidth > 0 ? (int)(xMean - 0.5f * NewWidth) : 0;
//    res.y           = yMean - 0.5f * NewHeight > 0 ? (int)(yMean - 0.5f * NewHeight) : 0;
//    if(NewWidth + res.x < imgSize.width)
//        res.width   = NewWidth;
//    else
//        res.width   = imgSize.width - res.x;
//    if(NewHeight*1.1f + res.y < imgSize.height)
//        res.height  = NewHeight*1.1f;
//    else
//        res.height  = imgSize.height - res.y;
//    //res.width = NewWidth < imgSize.width ? (int)NewWidth : imgSize.width;
//    //res.height = (NewHeight*1.1f) < imgSize.height ? (int)(NewHeight*1.1f) : imgSize.height;
//
//    return res;
//}


/**
 * @param        imgWidth       image size
 * @param        imgHeight      the detected face rectangle
 * @param        facepart       which face part is it?
 * @param        dir            face directions
 * @return       Rect           the possible rectangle for this specific face rectangle
 */
cv::Rect CFaceDetectionAlgs::VO_SetDetectedFacePartsPossibleWindow(int imgWidth, int imgHeight, unsigned int facepart, unsigned int dir)
{
    cv::Rect rect;
    switch(dir)
    {
    case LEFTPROFILE:
        break;
    case RIGHTPROFILE:
        break;
    case FRONTAL:
    default:
        {
            switch(facepart)
            {
            case VO_FacePart::LEFTEYE:
                rect    = cv::Rect ( ( int ) ( imgWidth/20.0f ), ( int ) ( imgHeight/20.0f ), ( int ) ( 9.0f*imgWidth/20.0f ), ( int ) ( 7*imgHeight/20.0f ) );
                break;
            case VO_FacePart::RIGHTEYE:
                rect    = cv::Rect ( ( int ) ( 1.0f*imgWidth/2.0f ), ( int ) ( imgHeight/20.0f ), ( int ) ( 9.0f*imgWidth/20.0f ), ( int ) ( 7*imgHeight/20.0f ) );
                break;
            case VO_FacePart::NOSE:
                rect    = cv::Rect ( ( int ) ( imgWidth/4.0f ), ( int ) ( imgHeight/5.0f ), ( int ) ( imgWidth/2.0f ), ( int ) ( 7.0*imgHeight/10.0f ) );
                break;
            case VO_FacePart::LIPOUTERLINE:
                rect    = cv::Rect ( ( int ) ( 0.1*imgWidth/1.0f ), ( int ) ( 1.0f*imgHeight/2.0f ), ( int ) ( 0.8f*imgWidth/1.0f ), ( int ) ( 1.0f*imgHeight/2.0f ) );
                break;
            case VO_FacePart::NOSECENTRALAREA:
                rect    = cv::Rect ( ( int ) ( 0.48*imgWidth ), ( int ) ( 0.45*imgHeight ), ( int ) ( 0.05*imgWidth ), ( int ) ( 0.10*imgHeight ) );
                break;
            default:
                break;
            }
        }
        break;
    }
    
    return rect;
}

